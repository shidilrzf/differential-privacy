{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import  DataLoader, Dataset, TensorDataset\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pyvacy import analysis\n",
    "from sampler import *\n",
    "from optimizer import DPSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "if use_cuda:\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.set_device(0)\n",
    "    print('GPU')\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST('data/mnist',train=True, download=True, transform=image_transform)\n",
    "test_dataset = datasets.MNIST('data/mnist',train=False, download=True, transform=image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, inp):\n",
    "        return inp.reshape(inp.shape[0], -1)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 8, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 1),\n",
    "            nn.Conv2d(16, 32, 4, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 1),\n",
    "            Flatten(),\n",
    "            nn.Linear(288, 10),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer = Classifier( input_dim=np.prod(train_dataset[0][0].shape)).to(device)\n",
    "\n",
    "l2_norm_clip = 1.5 # gradient clip\n",
    "noise_multiplier = 1.1 #random noise added\n",
    "microbatch_size = 1\n",
    "minibatch_size = 26\n",
    "lr = 0.15\n",
    "weight_decay = 0.001\n",
    "\n",
    "optimizer = DPSGD(l2_norm_clip = l2_norm_clip, noise_multiplier = noise_multiplier, \n",
    "                        minibatch_size = minibatch_size, microbatch_size = microbatch_size, \n",
    "                        params = classifer.parameters(), lr = lr, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, minibatch_size, microbatch_size, num_itr, device):\n",
    "\n",
    "    loss_function = nn.NLLLoss()\n",
    "\n",
    "    minibatch_loader, microbatch_loader = get_data_loaders(minibatch_size, microbatch_size, num_itr)\n",
    "\n",
    "    iteration = 0\n",
    "    for X_minibatch, y_minibatch in minibatch_loader(train_dataset):\n",
    "        optimizer.zero_grad()\n",
    "        for X_microbatch, y_microbatch in microbatch_loader(TensorDataset(X_minibatch, y_minibatch)):\n",
    "            X_microbatch = X_microbatch.to(device)\n",
    "            y_microbatch = y_microbatch.to(device)\n",
    "\n",
    "            optimizer.zero_microbatch_grad()\n",
    "            y_hat_microbatch = model(X_microbatch)\n",
    "            loss = loss_function(y_hat_microbatch, y_microbatch)\n",
    "            loss.backward()\n",
    "            optimizer.microbatch_step()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 10 == 0:\n",
    "            print('[Iteration %d/%d] [Loss: %f]' % (iteration, num_itr, loss.item()))\n",
    "        iteration += 1\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/14000] [Loss: 0.002892]\n",
      "[Iteration 10/14000] [Loss: 0.005150]\n",
      "[Iteration 20/14000] [Loss: 0.012867]\n",
      "[Iteration 30/14000] [Loss: 0.135098]\n",
      "[Iteration 40/14000] [Loss: 1.237598]\n",
      "[Iteration 50/14000] [Loss: 0.198805]\n",
      "[Iteration 60/14000] [Loss: 0.059972]\n",
      "[Iteration 70/14000] [Loss: 0.052361]\n",
      "[Iteration 80/14000] [Loss: 0.008646]\n",
      "[Iteration 90/14000] [Loss: 0.018140]\n",
      "[Iteration 100/14000] [Loss: 0.014385]\n",
      "[Iteration 110/14000] [Loss: 7.042806]\n",
      "[Iteration 120/14000] [Loss: 7.076878]\n",
      "[Iteration 130/14000] [Loss: 0.707346]\n",
      "[Iteration 140/14000] [Loss: 0.003904]\n",
      "[Iteration 150/14000] [Loss: 0.058160]\n",
      "[Iteration 160/14000] [Loss: 0.005450]\n",
      "[Iteration 170/14000] [Loss: 0.003870]\n",
      "[Iteration 180/14000] [Loss: 4.042059]\n",
      "[Iteration 190/14000] [Loss: 0.640369]\n",
      "[Iteration 200/14000] [Loss: 11.004584]\n",
      "[Iteration 210/14000] [Loss: 0.001165]\n",
      "[Iteration 220/14000] [Loss: 0.080393]\n",
      "[Iteration 230/14000] [Loss: 0.171749]\n",
      "[Iteration 240/14000] [Loss: 0.000008]\n",
      "[Iteration 250/14000] [Loss: 0.002382]\n",
      "[Iteration 260/14000] [Loss: 5.242554]\n",
      "[Iteration 270/14000] [Loss: 5.640312]\n",
      "[Iteration 280/14000] [Loss: 0.742948]\n",
      "[Iteration 290/14000] [Loss: 0.021154]\n",
      "[Iteration 300/14000] [Loss: 7.951867]\n",
      "[Iteration 310/14000] [Loss: 0.000036]\n",
      "[Iteration 320/14000] [Loss: 16.457085]\n",
      "[Iteration 330/14000] [Loss: 1.121628]\n",
      "[Iteration 340/14000] [Loss: 6.183557]\n",
      "[Iteration 350/14000] [Loss: 4.145767]\n",
      "[Iteration 360/14000] [Loss: 12.908520]\n",
      "[Iteration 370/14000] [Loss: 0.000875]\n",
      "[Iteration 380/14000] [Loss: 0.079399]\n",
      "[Iteration 390/14000] [Loss: 0.000950]\n",
      "[Iteration 400/14000] [Loss: 9.999212]\n",
      "[Iteration 410/14000] [Loss: 1.295622]\n",
      "[Iteration 420/14000] [Loss: 0.009068]\n",
      "[Iteration 430/14000] [Loss: 0.667812]\n",
      "[Iteration 440/14000] [Loss: 3.937469]\n",
      "[Iteration 450/14000] [Loss: 16.466019]\n",
      "[Iteration 460/14000] [Loss: 12.698286]\n",
      "[Iteration 470/14000] [Loss: 2.674095]\n",
      "[Iteration 480/14000] [Loss: 5.961040]\n",
      "[Iteration 490/14000] [Loss: 0.029573]\n",
      "[Iteration 500/14000] [Loss: 0.000000]\n",
      "[Iteration 510/14000] [Loss: 14.553387]\n",
      "[Iteration 520/14000] [Loss: 4.817949]\n",
      "[Iteration 530/14000] [Loss: 0.000000]\n",
      "[Iteration 540/14000] [Loss: 1.720957]\n",
      "[Iteration 550/14000] [Loss: 0.000000]\n",
      "[Iteration 560/14000] [Loss: 15.796932]\n",
      "[Iteration 570/14000] [Loss: 0.000000]\n",
      "[Iteration 580/14000] [Loss: 0.001383]\n",
      "[Iteration 590/14000] [Loss: 0.000000]\n",
      "[Iteration 600/14000] [Loss: 9.280466]\n",
      "[Iteration 610/14000] [Loss: 5.243912]\n",
      "[Iteration 620/14000] [Loss: 2.417196]\n",
      "[Iteration 630/14000] [Loss: 0.001358]\n",
      "[Iteration 640/14000] [Loss: 0.001602]\n",
      "[Iteration 650/14000] [Loss: 0.125465]\n",
      "[Iteration 660/14000] [Loss: 17.198170]\n",
      "[Iteration 670/14000] [Loss: 0.000019]\n",
      "[Iteration 680/14000] [Loss: 18.779306]\n",
      "[Iteration 690/14000] [Loss: 7.612515]\n",
      "[Iteration 700/14000] [Loss: 0.000000]\n",
      "[Iteration 710/14000] [Loss: 0.002651]\n",
      "[Iteration 720/14000] [Loss: 0.000000]\n",
      "[Iteration 730/14000] [Loss: 0.000000]\n",
      "[Iteration 740/14000] [Loss: 0.095490]\n",
      "[Iteration 750/14000] [Loss: 0.000000]\n",
      "[Iteration 760/14000] [Loss: 3.288223]\n",
      "[Iteration 770/14000] [Loss: 3.360573]\n",
      "[Iteration 780/14000] [Loss: 0.000000]\n",
      "[Iteration 790/14000] [Loss: 0.000034]\n",
      "[Iteration 800/14000] [Loss: 0.000000]\n",
      "[Iteration 810/14000] [Loss: 0.003899]\n",
      "[Iteration 820/14000] [Loss: 0.000000]\n",
      "[Iteration 830/14000] [Loss: 0.014496]\n",
      "[Iteration 840/14000] [Loss: 10.869987]\n",
      "[Iteration 850/14000] [Loss: 21.570494]\n",
      "[Iteration 860/14000] [Loss: 0.000000]\n",
      "[Iteration 870/14000] [Loss: 0.000000]\n",
      "[Iteration 880/14000] [Loss: 0.000000]\n",
      "[Iteration 890/14000] [Loss: 0.000008]\n",
      "[Iteration 900/14000] [Loss: 13.125704]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = train(classifer, optimizer, minibatch_size, microbatch_size, 14000, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-03f2e4b1d05c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "x, y = test_dataloader.__iter__().__next__()\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "y_pred = classifier(x).max(1)[1]\n",
    "\n",
    "count = 0.\n",
    "correct = 0.\n",
    "for pred, actual in zip(y_pred, y):\n",
    "    if pred.item() == actual.item():\n",
    "        correct += 1.\n",
    "    count += 1.\n",
    "print('Test Accuracy: {}'.format(correct / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
